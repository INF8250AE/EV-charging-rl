defaults:
  - _self_
  - algo: ddqn
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d_%H-%M-%S}/${algo.name}_${experiment.type}
experiment:
  type: "train_agent"
logging:
  fps: 4
  use_cometml: true
  verbose_log_ep_interval : 100
  save_model_step_freq: 50_000 
  step_logging_freq: 1000
  video_start_every: 50_000
  video_frames_per_clip: 120
  video_snapshot_every: 1
training:
  nb_env_steps: 500_000
  seed: 42
  batch_size: 64
env:
  _partial_: true
  _target_: ev_charging.env.EvChargingEnv
  device: "cpu"
  advance_until_next_request: true
  nb_stations: 3
  min_charge_speed: 5
  max_charge_speed: 10
  min_charge_speed_sharpness: 1
  max_charge_speed_sharpness: 5
  min_chargers_per_station: 1
  max_chargers_per_station: 4
  min_travel_time_to_station: 2
  max_travel_time_to_station: 15
  min_mean_travel_time_to_station: 3
  max_mean_travel_time_to_station: 10
  min_std_travel_time_to_station: 0.5
  max_std_travel_time_to_station: 2.0
  max_nb_cars_traveling_to_station: 4
  max_nb_cars_waiting_at_station: 2
  min_car_capacity: 200
  max_car_capacity: 500
  max_car_init_soc: 0.7
  min_steps_between_arrivals: 1
  max_steps_between_arrivals: 3
  max_steps: 500
  reward_congestion_weight: -0.5
  reward_urgency_weight: -0.1
  reward_energy_weight: 0.3
  reward_charged_cars_weight: 0.5
  reward_station_full_penalty: 3.0